{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> MobileNetV2 x1.4 Adversarial Example Generation </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using HopSkipJump un-targeted attack algorithm to generate adversarial examples using the Adversarial - Robustness - Toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries and Definitions.\n",
    "\n",
    "We use 0 seed to maintain reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.quantization import MovingAverageMinMaxObserver\n",
    "from torch.ao.quantization.observer import MinMaxObserver\n",
    "from torch.quantization import QuantStub, DeQuantStub\n",
    "import torch.nn as nn\n",
    "import urllib\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.utils import load_cifar10\n",
    "from art.preprocessing.standardisation_mean_std import StandardisationMeanStdPyTorch\n",
    "from art.attacks.evasion.hop_skip_jump import HopSkipJump\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "from math import log10, sqrt\n",
    "import  random\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "def PSNR(original, compressed):\n",
    "    mse = np.mean((original - compressed) ** 2)\n",
    "    epsilon = 1e-10  # Small epsilon to avoid division by zero\n",
    "    mse = max(mse, epsilon)  # Ensure MSE is not zero\n",
    "    max_pixel = 1.0\n",
    "    psnr = 20 * log10(max_pixel / sqrt(mse))\n",
    "    return psnr\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "def print_size_of_model(model):\n",
    "    \"\"\" Prints the real size of the model \"\"\"\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')\n",
    "\n",
    "    \n",
    "def accuracy(output, target):\n",
    "    \"\"\" Computes the top 1 accuracy \"\"\"\n",
    "    with torch.no_grad():\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(1, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        correct_one = correct[:1].view(-1).float().sum(0, keepdim=True)\n",
    "        return correct_one.mul_(100.0 / batch_size).item()\n",
    "\n",
    "def normalize_np(img):\n",
    "  img = torch.from_numpy(img)\n",
    "  img = F.normalize(img, [0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "  return img.numpy()\n",
    "\n",
    "\n",
    "def test(model: nn.Module, dataloader: DataLoader, cuda=False) -> float:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            inputs, labels = data\n",
    "            if cuda:\n",
    "              inputs = inputs.cuda()\n",
    "              labels = labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the CIFAR10 dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), min_pixel_value, max_pixel_value = load_cifar10()\n",
    "\n",
    "# Step 1a: Swap axes to PyTorch's NCHW format\n",
    "\n",
    "x_train = np.transpose(x_train, (0, 3, 1, 2)).astype(np.float32)\n",
    "x_test = np.transpose(x_test, (0, 3, 1, 2)).astype(np.float32)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "test_data = datasets.CIFAR10(root=\"./data\",train=False,download=True,transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=64)\n",
    "\n",
    "# show images\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Examples Dataset Generation\n",
    "\n",
    "The following code generates adversarial examples for each model \"version\".\n",
    "\n",
    "1. 30000 examples\n",
    "2. 20000 examples\n",
    "3. 10000 examples\n",
    "\n",
    "Due to the amount of images processed, we split each loop into 300s, 200s, 100s respectively.\n",
    "In the end, each dataset is consisted of 100 files which we merge into one. \n",
    "The files are available on the drive link if you are interested.\n",
    "\n",
    "Each of the following blocks loads the corresponding model and generates its examples for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------     FIRST ADVERSARIAL EXAMPLE GENERATION ----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_mobilenetv2_x1_4\", pretrained=True)\n",
    "model.to(\"cuda\")\n",
    "model.eval()\n",
    "model.float()\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Define the optimizer used for each model (Fully optional, can be omitted)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, dampening=0,weight_decay=0.0005, nesterov=True)\n",
    "\n",
    "\n",
    "score = test(model, test_loader, cuda=True)\n",
    "print('Initial accuracy on test images: {}% - FP32'.format(score))\n",
    "\n",
    "# Create the ART - PyTorch classifier\n",
    "classifier = PyTorchClassifier(\n",
    "    model=model,\n",
    "    clip_values=(0.0, 1.0),\n",
    "    loss=criterion,\n",
    "    optimizer=optimizer,\n",
    "    preprocessing=((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)), #Normalization step shouldn't happen at the data. It's inserted here.\n",
    "    input_shape=(3, 32, 32),\n",
    "    nb_classes=10,\n",
    "    device_type = \"gpu\"\n",
    ")\n",
    "print(\"HopSkipJump Attack Initialization\")\n",
    "\n",
    "attack = HopSkipJump(classifier,64,targeted = False,verbose = True)\n",
    "\n",
    "for i in range(0,100):\n",
    "    x_train_hop_mobile_cifar = attack.generate(normalize_np(x_train[0+300*i:300*(i+1)]),y_train[0+300*i:300*(i+1)])\n",
    "    with open(\"x_1_train_hop_mobile_cifar_{}_to_{}.pkl\".format(300*i,300*(i+1)),'wb') as f:\n",
    "        pickle.dump(x_train_hop_mobile_cifar,f)\n",
    "    with open(\"mobilenet_1cifar_progress.txt\",'wb') as f:\n",
    "        f.write(\"Done with {}\\n\".format(300*(i+1)))\n",
    "    print(\"{} Examples generated.\".format(300*(i+1)))\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------     SECOND ADVERSARIAL TRAINING ITERATION ----------------------------------------------------------------------\n",
    "\n",
    "################################################################################################################################################\n",
    "\"\"\"REMINDER: Load the retrained model, not the initial.\"\"\"\n",
    "\n",
    "\n",
    "adversarial_state = urllib.request.urlopen(\"https://drive.usercontent.google.com/download?id=1umVJExm8VeVSqIpEWlCVhMbJrNZeU-aw&export=download&confirm=t&uuid=0\")\n",
    "\n",
    "\"\"\"\n",
    "If you want to manually load the file or load your own model version, use the code below updating your path accordingly\n",
    "\n",
    "# Adversarial Model 1 https://drive.google.com/file/d/1umVJExm8VeVSqIpEWlCVhMbJrNZeU-aw/view?usp=sharing\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#path = \"~/Downloads/\"\n",
    "\n",
    "#adversarial_state = os.path.join(path, \"MobileNet_1it_CIFAR10_94.17acc.pkl\")\n",
    "\n",
    "model.load_state_dict(torch.load(adversarial_state))\n",
    "model.float()\n",
    "model.eval()\n",
    "################################################################################################################################################\n",
    "\n",
    "\n",
    "#Define the optimizer used for each model (Fully optional, can be omitted)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "score = test(model, test_loader, cuda=True)\n",
    "print('Initial accuracy on test images: {}% - FP32'.format(score))\n",
    "\n",
    "# Create the ART - PyTorch classifier\n",
    "classifier = PyTorchClassifier(\n",
    "    model=model,\n",
    "    clip_values=(0.0, 1.0),\n",
    "    loss=criterion,\n",
    "    optimizer=optimizer,\n",
    "    preprocessing=((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)), #Normalization step shouldn't happen at the data. It's inserted here.\n",
    "    input_shape=(3, 32, 32),\n",
    "    nb_classes=10,\n",
    "    device_type = \"gpu\"\n",
    ")\n",
    "print(\"HopSkipJump Attack Initialization\")\n",
    "\n",
    "attack = HopSkipJump(classifier,64,targeted = False,verbose = True)\n",
    "\n",
    "for i in range(0,100):\n",
    "    x_train_hop_mobile_cifar = attack.generate(normalize_np(x_train[0+300*i:300*(i+1)]),y_train[0+300*i:300*(i+1)])\n",
    "    with open(\"x_2_train_hop_mobile_cifar_{}_to_{}.pkl\".format(300*i,300*(i+1)),'wb') as f:\n",
    "        pickle.dump(x_train_hop_mobile_cifar,f)\n",
    "    with open(\"mobilenet_2cifar_progress.txt\",'wb') as f:\n",
    "        f.write(\"Done with {}\\n\".format(300*(i+1)))\n",
    "    print(\"{} Examples generated.\".format(300*(i+1)))\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------     THIRD ADVERSARIAL TRAINING ITERATION ----------------------------------------------------------------------\n",
    "\n",
    "################################################################################################################################################\n",
    "\"\"\"REMINDER: Load the retrained model, not the initial.\"\"\"\n",
    "\n",
    "adversarial_state = urllib.request.urlopen(\"https://drive.usercontent.google.com/download?id=12Ux4pWLxK4gTr54eMN-Mds4adPMvjfNX&export=download&confirm=t&uuid=0\")\n",
    "\n",
    "\"\"\"\n",
    "If you want to manually load the file or load your own model version, use the code below updating your path accordingly\n",
    "\n",
    "# Adversarial Model 2 https://drive.google.com/file/d/12Ux4pWLxK4gTr54eMN-Mds4adPMvjfNX/view?usp=sharing\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#path = \"~/Downloads/\"\n",
    "\n",
    "#adversarial_state = os.path.join(path, \"MobileNet_2it_CIFAR10_93.58acc.pkl\")\n",
    "\n",
    "model.load_state_dict(torch.load(adversarial_state))\n",
    "model.float()\n",
    "model.eval()\n",
    "################################################################################################################################################\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Define the optimizer used for each model (Fully optional, can be omitted)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-7)\n",
    "\n",
    "\n",
    "score = test(model, test_loader, cuda=True)\n",
    "print('Initial accuracy on test images: {}% - FP32'.format(score))\n",
    "\n",
    "# Create the ART - PyTorch classifier\n",
    "classifier = PyTorchClassifier(\n",
    "    model=model,\n",
    "    clip_values=(0.0, 1.0),\n",
    "    loss=criterion,\n",
    "    optimizer=optimizer,\n",
    "    preprocessing=((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)), #Normalization step shouldn't happen at the data. It's inserted here.\n",
    "    input_shape=(3, 32, 32),\n",
    "    nb_classes=10,\n",
    "    device_type = \"gpu\"\n",
    ")\n",
    "print(\"HopSkipJump Attack Initialization\")\n",
    "\n",
    "attack = HopSkipJump(classifier,64,targeted = False,verbose = True)\n",
    "\n",
    "for i in range(0,100):\n",
    "    x_train_hop_mobile_cifar = attack.generate(normalize_np(x_train[0+300*i:300*(i+1)]),y_train[0+300*i:300*(i+1)])\n",
    "    with open(\"x_3_train_hop_mobile_cifar_{}_to_{}.pkl\".format(300*i,300*(i+1)),'wb') as f:\n",
    "        pickle.dump(x_train_hop_mobile_cifar,f)\n",
    "    with open(\"mobilenet_3cifar_progress.txt\",'wb') as f:\n",
    "        f.write(\"Done with {}\\n\".format(300*(i+1)))\n",
    "    print(\"{} Examples generated.\".format(300*(i+1)))\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
