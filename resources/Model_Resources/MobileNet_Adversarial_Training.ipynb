{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> MobileNetV2 x1.4 Adversarial Training on Generated Examples </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Definitions.\n",
    "\n",
    "We use seed 0 throughout our codes to ensure reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.quantization import MovingAverageMinMaxObserver\n",
    "from torch.ao.quantization.observer import MinMaxObserver\n",
    "from torch.quantization import QuantStub, DeQuantStub\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.utils import load_cifar10\n",
    "from art.preprocessing.standardisation_mean_std import StandardisationMeanStdPyTorch\n",
    "from art.attacks.evasion.hop_skip_jump import HopSkipJump\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "from math import log10, sqrt\n",
    "import cv2\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Definitions.\n",
    "\n",
    "Standard Average meter and test function along with a custom testing function \"accuracy\".\n",
    "Training function is included later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test(model: nn.Module, dataloader: DataLoader, cuda=False) -> float:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            inputs, labels = data\n",
    "            if cuda:\n",
    "              inputs = inputs.cuda()\n",
    "              labels = labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "def accuracy(output, target):\n",
    "    \"\"\" Computes the top 1 accuracy \"\"\"\n",
    "    with torch.no_grad():\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(1, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        correct_one = correct[:1].view(-1).float().sum(0, keepdim=True)\n",
    "        return correct_one.mul_(100.0 / batch_size).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project specific functions.\n",
    "\n",
    "\"normalize_np\" Applies the same Mean and Std of the tensor CIFAR-10 Dataset to the Numpy one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(original, compressed):\n",
    "    mse = np.mean((original - compressed) ** 2)\n",
    "    epsilon = 1e-10  # Small epsilon to avoid division by zero\n",
    "    mse = max(mse, epsilon)  # Ensure MSE is not zero\n",
    "    max_pixel = 1.0\n",
    "    psnr = 20 * log10(max_pixel / sqrt(mse))\n",
    "    return psnr\n",
    "\n",
    "def show_image(img):\n",
    "    plt.imshow(img)\n",
    "    plt.show(block=False)\n",
    "    \n",
    "def normalize_np(img):\n",
    "  img = torch.from_numpy(img)\n",
    "  img = F.normalize(img, [0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "  return img.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the CIFAR10 dataset from ART\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), min_pixel_value, max_pixel_value = load_cifar10()\n",
    "\n",
    "#Convert to PyTorch's NCHW format\n",
    "\n",
    "x_train = np.transpose(x_train, (0, 3, 1, 2)).astype(np.float32)\n",
    "x_test = np.transpose(x_test, (0, 3, 1, 2)).astype(np.float32)\n",
    "\n",
    "\n",
    "# also Load the Pytorch CIFAR-10 tensor dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,shuffle=True, num_workers=16, pin_memory=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,shuffle=False, num_workers=16, pin_memory=True)\n",
    "\n",
    "# Set image labels\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "\n",
    "# Sanity Check: Show first 5 images of CIFAR-10 (numpy version)\n",
    "printable = torchvision.utils.make_grid(torch.from_numpy(x_train[0:5])).numpy()\n",
    "printable = np.transpose(printable, (1, 2, 0) )\n",
    "show_image(printable)\n",
    "\n",
    "# Sanity Check: Include the adjusted versions (should be \"high contrast\")\n",
    "printable_norm = torchvision.utils.make_grid(torch.from_numpy(normalize_np(x_train)[0:5])).numpy()\n",
    "printable_norm = np.transpose(printable_norm, (1, 2, 0) )\n",
    "show_image(printable_norm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Examples Dataset\n",
    "\n",
    "Here you have 2 options.\n",
    "1. Download the datasets manually and update the paths.\n",
    "2. Let the notebook download and load them.\n",
    "\n",
    "Run the corresponding block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Adversarial Set 1 https://drive.google.com/file/d/1NdiiJ2hBOuzU7YZyK1p0dNkWlbHriqLD/view?usp=sharing\n",
    "\n",
    "# Adversarial Set 2 https://drive.google.com/file/d/14GE6vJhgUJvy5SLerDdy1V0OEVWDOryd/view?usp=sharing\n",
    "\n",
    "# Adversarial Set 3 https://drive.google.com/file/d/1NGyjybPJpXaRPsKfICI0vN3CbADB--o5/view?usp=sharing\n",
    "\n",
    "\n",
    "#Your path to downloaded files\n",
    "path = \"~/Downloads/\"\n",
    "\n",
    "file1 = open(os.path.join(path, \"train_mobilenet_hop_cifar_for_1it.pkl\"),'rb')\n",
    "file2 = open(os.path.join(path, \"train_mobilenet_hop_cifar_for_2it.pkl\"),'rb')\n",
    "file3 = open(os.path.join(path, \"train_mobilenet_hop_cifar_for_3it.pkl\"),'rb')\n",
    "\n",
    "adversarial_1 = pickle.load(file1)\n",
    "adversarial_2 = pickle.load(file2)\n",
    "adversarial_3 = pickle.load(file3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load by Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "adversarial_1 = pickle.load(urllib.request.urlopen(\"https://drive.usercontent.google.com/download?id=1NdiiJ2hBOuzU7YZyK1p0dNkWlbHriqLD&export=download&confirm=t&uuid=0\"))\n",
    "adversarial_2 = pickle.load(urllib.request.urlopen(\"https://drive.usercontent.google.com/download?id=14GE6vJhgUJvy5SLerDdy1V0OEVWDOryd&export=download&confirm=t&uuid=0\"))\n",
    "adversarial_3 = pickle.load(urllib.request.urlopen(\"https://drive.usercontent.google.com/download?id=1NGyjybPJpXaRPsKfICI0vN3CbADB--o5&export=download&confirm=t&uuid=0\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    # Combine a list of samples into a batch\n",
    "    data, labels = zip(*batch)\n",
    "    data = torch.stack(data)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Adversarial Example dataset (30k examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 30000\n",
    "\n",
    "x_train_set = adversarial_1[0:sample_size]\n",
    "y_train_set = np.empty((sample_size)).astype(np.int8)\n",
    "\n",
    "# Remove 1 hot encoding\n",
    "for i in range(sample_size):\n",
    "    y_train_set[i] = np.where(y_train[i] == 1)[0][0]\n",
    "    \n",
    "print(x_train_set.shape, y_train_set.shape)\n",
    "\n",
    "\n",
    "trainingSet = torch.utils.data.TensorDataset(torch.from_numpy(normalize_np(x_train_set)).type(torch.FloatTensor), torch.from_numpy(y_train_set).type(torch.LongTensor))\n",
    "\n",
    "train_dev_sets = torch.utils.data.ConcatDataset([trainingSet])\n",
    "\n",
    "\n",
    "\n",
    "retrain_loader_1 = torch.utils.data.DataLoader(dataset=train_dev_sets, batch_size=64, num_workers=16, pin_memory=True, shuffle=True, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second Adversarial Example dataset (20k examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 20000\n",
    "\n",
    "x_train_set = adversarial_2[0:sample_size]\n",
    "y_train_set = np.empty((sample_size)).astype(np.int8)\n",
    "\n",
    "# Remove 1 hot encoding\n",
    "for i in range(sample_size):\n",
    "    y_train_set[i] = np.where(y_train[i] == 1)[0][0]\n",
    "    \n",
    "print(x_train_set.shape, y_train_set.shape)\n",
    "\n",
    "\n",
    "trainingSet = torch.utils.data.TensorDataset(torch.from_numpy(normalize_np(x_train_set)).type(torch.FloatTensor), torch.from_numpy(y_train_set).type(torch.LongTensor))\n",
    "\n",
    "train_dev_sets = torch.utils.data.ConcatDataset([trainingSet])\n",
    "\n",
    "\n",
    "\n",
    "retrain_loader_2 = torch.utils.data.DataLoader(dataset=train_dev_sets, batch_size=64, num_workers=16, pin_memory=True, shuffle=True, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third Adversarial Example dataset (10k examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 10000\n",
    "\n",
    "x_train_set = adversarial_3[0:sample_size]\n",
    "y_train_set = np.empty((sample_size)).astype(np.int8)\n",
    "\n",
    "# Remove 1 hot encoding\n",
    "for i in range(sample_size):\n",
    "    y_train_set[i] = np.where(y_train[i] == 1)[0][0]\n",
    "    \n",
    "print(x_train_set.shape, y_train_set.shape)\n",
    "\n",
    "\n",
    "trainingSet = torch.utils.data.TensorDataset(torch.from_numpy(normalize_np(x_train_set)).type(torch.FloatTensor), torch.from_numpy(y_train_set).type(torch.LongTensor))\n",
    "\n",
    "train_dev_sets = torch.utils.data.ConcatDataset([trainingSet])\n",
    "\n",
    "\n",
    "\n",
    "retrain_loader_3 = torch.utils.data.DataLoader(dataset=train_dev_sets, batch_size=64, num_workers=16, pin_memory=True, shuffle=True, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Retraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training process is split into three steps.\n",
    "Here you also have 2 choices.\n",
    "\n",
    "In this notebook, we start from the initial model and retrain it 3 times.\n",
    "\n",
    "On \"Adver_Train_separate\" folder, we include the retraining process split in 3 steps where we load the already trained version in each one.\n",
    "Ideally we want them separately to retrieve the trained model and generate adversarial examples on it for our next iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------     FIRST ADVERSARIAL TRAINING ITERATION ----------------------------------------------------------------------\n",
    "\n",
    "def train(model: nn.Module, advloader: DataLoader,testloader: DataLoader, cuda=False):\n",
    "\n",
    "    #The flag's purpose is to stop the model on the previously achieved accuracies. Feel free to change/remove it.\n",
    "    flagged = False\n",
    "\n",
    "    #For the first iteration we use SGD optimizer. Later on we switch to Adam\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9, dampening=0,weight_decay=0.0005, nesterov=True)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(400):  # Define your max training epochs\n",
    "        if flagged:\n",
    "            break   # Training pause flag on pre-determined accuracies.\n",
    "        else:\n",
    "            #Typical training procedure\n",
    "            running_loss = AverageMeter('loss')\n",
    "            acc = AverageMeter('train_acc')\n",
    "            for i, data in enumerate(advloader, 0):\n",
    "        \n",
    "                inputs, labels = data\n",
    "                if cuda:\n",
    "                  inputs = inputs.cuda()\n",
    "                  labels = labels.cuda()\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward + backward + optimize\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                # print statistics\n",
    "                running_loss.update(loss.item(), outputs.shape[0])\n",
    "                acc.update(accuracy(outputs, labels), outputs.shape[0])\n",
    "                if i % 100 == 0:    # print every 100 mini-batches\n",
    "                    print('[%d, %5d] ' %\n",
    "                        (epoch + 1, i + 1), running_loss, acc)\n",
    "                    \n",
    "            #--------- REMOVABLE PART ----------\n",
    "            #Test model after each epoch on test and adversarial sets\n",
    "\n",
    "            score = test(model, testloader, cuda=True)\n",
    "            score1 = test(model, advloader, cuda=True)\n",
    "            print('Current Epoch {} : Test Set accuracy: {}% - FP32'.format(epoch, score))\n",
    "            print('Current Epoch {} : Adversarial Example set accuracy: {}% - FP32'.format(epoch, score1))\n",
    "            #  IF x and y scores achieved, stop training.\n",
    "            if (score >= 94.10 and score1 >= 99.99):\n",
    "                flagged = True\n",
    "            model.train()\n",
    "\n",
    "            #   NOTE: THIS CAN AND WILL SUBSTANTIALLY AFFECT TRAINING TIME AND PERFORMANCE.\n",
    "            #   If you want the achieved accuracies its better to load the intermediate model weights provided.\n",
    "\n",
    "            #-----------------------------------\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "\n",
    "#1st retraining: Load pretrained model.\n",
    "\n",
    "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_mobilenetv2_x1_4\", pretrained=True)\n",
    "model.to(\"cuda\")\n",
    "model.eval()\n",
    "\n",
    "#Initial Accuracy\n",
    "score = test(model, testloader, cuda=True)\n",
    "print('Initial accuracy of the network on test images: {}% - FP32'.format(score))\n",
    "\n",
    "train(model,retrain_loader_1,testloader,cuda=True)\n",
    "\n",
    "#After training\n",
    "score = test(model, testloader, cuda=True)\n",
    "print('After 1 Adversarial Training of the network: Accuracy on test images: {}% - FP32'.format(score))\n",
    "\n",
    "#Save model for later use\n",
    "torch.save(model.state_dict(), \"MobileNetV2_x1_4_AdvTrain1_CIF10_{}acc.pkl\".format(score))\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------     SECOND ADVERSARIAL TRAINING ITERATION ----------------------------------------------------------------------\n",
    "\n",
    "def train(model: nn.Module, advloader: DataLoader,testloader: DataLoader, cuda=False):\n",
    "\n",
    "    #The flag's purpose is to stop the model on the previously achieved accuracies. Feel free to change/remove it.\n",
    "    flagged = False\n",
    "\n",
    "    #Switch to Adam increasing generalization\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(400):  # Define your max training epochs\n",
    "        if flagged:\n",
    "            break   # Training pause flag on pre-determined accuracies.\n",
    "        else:\n",
    "            #Typical training procedure\n",
    "            running_loss = AverageMeter('loss')\n",
    "            acc = AverageMeter('train_acc')\n",
    "            for i, data in enumerate(advloader, 0):\n",
    "        \n",
    "                inputs, labels = data\n",
    "                if cuda:\n",
    "                  inputs = inputs.cuda()\n",
    "                  labels = labels.cuda()\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward + backward + optimize\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                # print statistics\n",
    "                running_loss.update(loss.item(), outputs.shape[0])\n",
    "                acc.update(accuracy(outputs, labels), outputs.shape[0])\n",
    "                if i % 100 == 0:    # print every 100 mini-batches\n",
    "                    print('[%d, %5d] ' %\n",
    "                        (epoch + 1, i + 1), running_loss, acc)\n",
    "                    \n",
    "            #--------- REMOVABLE PART ----------\n",
    "            #Test model after each epoch on test and adversarial sets\n",
    "\n",
    "            score = test(model, testloader, cuda=True)\n",
    "            score1 = test(model, advloader, cuda=True)\n",
    "            print('Current Epoch {} : Test Set accuracy: {}% - FP32'.format(epoch, score))\n",
    "            print('Current Epoch {} : Adversarial Example set accuracy: {}% - FP32'.format(epoch, score1))\n",
    "            #  IF x and y scores achieved, stop training.\n",
    "            if (score >= 93.55 and score1 >= 99.98):\n",
    "                flagged = True\n",
    "            model.train()\n",
    "\n",
    "            #   NOTE: THIS CAN AND WILL SUBSTANTIALLY AFFECT TRAINING TIME AND PERFORMANCE.\n",
    "            #   If you want the achieved accuracies its better to load the intermediate model weights provided.\n",
    "\n",
    "            #-----------------------------------\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "\n",
    "#2nd retraining: Model Loaded.\n",
    "model.eval()\n",
    "\n",
    "#Initial Accuracy\n",
    "score = test(model, testloader, cuda=True)\n",
    "print('Sanity Check: Adversarial Training 1: accuracy on test images: {}% - FP32'.format(score))\n",
    "\n",
    "train(model,retrain_loader_2,testloader,cuda=True)\n",
    "\n",
    "#After training\n",
    "score = test(model, testloader, cuda=True)\n",
    "print('After 2nd Adversarial Training of the network: Accuracy on test images: {}% - FP32'.format(score))\n",
    "\n",
    "#Save model for later use\n",
    "torch.save(model.state_dict(), \"MobileNetV2_x1_4_AdvTrain2_CIF10_{}acc.pkl\".format(score))\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------     THIRD ADVERSARIAL TRAINING ITERATION ----------------------------------------------------------------------\n",
    "\n",
    "def train(model: nn.Module, advloader: DataLoader,testloader: DataLoader, cuda=False):\n",
    "\n",
    "    #The flag's purpose is to stop the model on the previously achieved accuracies. Feel free to change/remove it.\n",
    "    flagged = False\n",
    "\n",
    "    #Keep Adam optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=5e-7)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(400):  # Define your max training epochs\n",
    "        if flagged:\n",
    "            break   # Training pause flag on pre-determined accuracies.\n",
    "        else:\n",
    "            #Typical training procedure\n",
    "            running_loss = AverageMeter('loss')\n",
    "            acc = AverageMeter('train_acc')\n",
    "            for i, data in enumerate(advloader, 0):\n",
    "        \n",
    "                inputs, labels = data\n",
    "                if cuda:\n",
    "                  inputs = inputs.cuda()\n",
    "                  labels = labels.cuda()\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward + backward + optimize\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                # print statistics\n",
    "                running_loss.update(loss.item(), outputs.shape[0])\n",
    "                acc.update(accuracy(outputs, labels), outputs.shape[0])\n",
    "                if i % 100 == 0:    # print every 100 mini-batches\n",
    "                    print('[%d, %5d] ' %\n",
    "                        (epoch + 1, i + 1), running_loss, acc)\n",
    "                    \n",
    "            #--------- REMOVABLE PART ----------\n",
    "            #Test model after each epoch on test and adversarial sets\n",
    "\n",
    "            score = test(model, testloader, cuda=True)\n",
    "            score1 = test(model, advloader, cuda=True)\n",
    "            print('Current Epoch {} : Test Set accuracy: {}% - FP32'.format(epoch, score))\n",
    "            print('Current Epoch {} : Adversarial Example set accuracy: {}% - FP32'.format(epoch, score1))\n",
    "            #  IF x and y scores achieved, stop training.\n",
    "            if (score >= 92.75 and score1 >= 98.70):\n",
    "                flagged = True\n",
    "            model.train()\n",
    "\n",
    "            #   NOTE: THIS CAN AND WILL SUBSTANTIALLY AFFECT TRAINING TIME AND PERFORMANCE.\n",
    "            #   If you want the achieved accuracies its better to load the intermediate model weights provided.\n",
    "\n",
    "            #-----------------------------------\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "\n",
    "#3rd retraining: Inplace model.\n",
    "model.eval()\n",
    "\n",
    "#Initial Accuracy\n",
    "score = test(model, testloader, cuda=True)\n",
    "print('Sanity Check: Adversarial Training 2: accuracy on test images: {}% - FP32'.format(score))\n",
    "\n",
    "train(model,retrain_loader_3,testloader,cuda=True)\n",
    "\n",
    "#After training\n",
    "score = test(model, testloader, cuda=True)\n",
    "print('After 3rd Adversarial Training of the network: Accuracy on test images: {}% - FP32'.format(score))\n",
    "#Save model for later use\n",
    "torch.save(model.state_dict(), \"MobileNetV2_x1_4_AdvTrain3_CIF10_{}acc.pkl\".format(score))\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
