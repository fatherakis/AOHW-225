{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> MobileNetV2 x1.4 Metrics and generation </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook adversarial examples are generated on each model version (quantized and fp) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from math import log10, sqrt\n",
    "from torch.utils.data import DataLoader\n",
    "from art.utils import load_cifar10\n",
    "import random\n",
    "import urllib\n",
    "from torch.quantization import MovingAverageMinMaxObserver\n",
    "from torch.ao.quantization.observer import MinMaxObserver\n",
    "from torch.quantization import QuantStub, DeQuantStub\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.utils import load_cifar10\n",
    "from art.preprocessing.standardisation_mean_std import StandardisationMeanStdPyTorch\n",
    "from art.attacks.evasion.hop_skip_jump import HopSkipJump\n",
    "from scipy.stats.mstats import gmean\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "def PSNR(original, compressed):\n",
    "    mse = np.mean((original - compressed) ** 2)\n",
    "    epsilon = 1e-10  # Small epsilon to avoid division by zero\n",
    "    mse = max(mse, epsilon)  # Ensure MSE is not zero\n",
    "    max_pixel = 1.0\n",
    "    psnr = 20 * log10(max_pixel / sqrt(mse))\n",
    "    return psnr\n",
    "\n",
    "def test(model: nn.Module, dataloader: DataLoader, cuda=False) -> float:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            inputs, labels = data\n",
    "            if cuda:\n",
    "              inputs = inputs.cuda()\n",
    "              labels = labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "def normalize_np(img):\n",
    "  img = torch.from_numpy(img)\n",
    "  img = F.normalize(img, [0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "  return img.numpy()\n",
    "\n",
    "def custom_collate(batch):\n",
    "        # Combine a list of samples into a batch\n",
    "        data, labels = zip(*batch)\n",
    "        data = torch.stack(data)\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "        return data, labels\n",
    "\n",
    "def evaluator(model, loader):\n",
    "  model.eval()\n",
    "  top_1 = 0\n",
    "  top_5 = 0\n",
    "  with torch.no_grad():\n",
    "    for data in loader:\n",
    "      inputs, labels = data\n",
    "      outputs = model(inputs)\n",
    "\n",
    "      _, predicted = torch.max(outputs, 1, keepdim=True)\n",
    "      top_1 += torch.sum(predicted.view(-1) == labels).item()\n",
    "\n",
    "      _, predicted_5 = torch.topk(outputs, k=5, dim=1)\n",
    "      top_5 += torch.sum(predicted_5 == labels.unsqueeze(1)).item()\n",
    "\n",
    "  return (\"{:.2f}\".format((top_1/400) * 100), \"{:.2f}\".format((top_5/400) * 100))\n",
    "\n",
    "def evaluator_testset(model, loader):\n",
    "  model.eval()\n",
    "  top_1 = 0\n",
    "  top_5 = 0\n",
    "  with torch.no_grad():\n",
    "    for data in loader:\n",
    "      inputs, labels = data\n",
    "      outputs = model(inputs)\n",
    "\n",
    "      _, predicted = torch.max(outputs, 1, keepdim=True)\n",
    "      top_1 += torch.sum(predicted.view(-1) == labels).item()\n",
    "\n",
    "      _, predicted_5 = torch.topk(outputs, k=5, dim=1)\n",
    "      top_5 += torch.sum(predicted_5 == labels.unsqueeze(1)).item()\n",
    "\n",
    "  return (\"{:.2f}\".format((top_1/10000) * 100), \"{:.2f}\".format((top_5/10000) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test), min_pixel_value, max_pixel_value = load_cifar10()\n",
    "\n",
    "x_train = np.transpose(x_train, (0, 3, 1, 2)).astype(np.float32)\n",
    "x_test = np.transpose(x_test, (0, 3, 1, 2)).astype(np.float32)\n",
    "\n",
    "classes_cifar = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "y_test_set = np.zeros((400,),np.int8)\n",
    "\n",
    "y_train_set = np.zeros((400,),np.int8)\n",
    "\n",
    "\n",
    "for i in range(400):\n",
    "        y_test_set[i] = np.where(y_test[i] == 1)[0][0]\n",
    "\n",
    "for i in range(400):\n",
    "        y_train_set[i] = np.where(y_train[i] == 1)[0][0]\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNetV2 Definition for quantized variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Dict, Type, Any, Callable, Union, List, Optional\n",
    "from torch import Tensor\n",
    "try:\n",
    "    from torch.hub import load_state_dict_from_url\n",
    "except ImportError:\n",
    "    from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
    "from torch.ao.nn.quantized.modules.functional_modules import FloatFunctional\n",
    "\n",
    "def _make_divisible(v: float, divisor: int, min_value: Optional[int] = None) -> int:\n",
    "    \"\"\"\n",
    "    This function is taken from the original tf repo.\n",
    "    It ensures that all layers have a channel number that is divisible by 8\n",
    "    It can be seen here:\n",
    "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    \"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        f_add = torch.nn.quantized.FloatFunctional()\n",
    "        new_v = f_add.add(new_v, divisor)\n",
    "        #new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "class ConvBNActivation(nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_planes: int,\n",
    "        out_planes: int,\n",
    "        kernel_size: int = 3,\n",
    "        stride: int = 1,\n",
    "        groups: int = 1,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "        activation_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "        dilation: int = 1,\n",
    "    ) -> None:\n",
    "        padding = (kernel_size - 1) // 2 * dilation\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if activation_layer is None:\n",
    "            activation_layer = nn.ReLU6\n",
    "        super(ConvBNReLU, self).__init__(\n",
    "            nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding, dilation=dilation, groups=groups,\n",
    "                      bias=False),\n",
    "            norm_layer(out_planes),\n",
    "            activation_layer(inplace=True)\n",
    "        )\n",
    "        self.out_channels = out_planes\n",
    "\n",
    "\n",
    "# necessary for backwards compatibility\n",
    "ConvBNReLU = ConvBNActivation\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inp: int,\n",
    "        oup: int,\n",
    "        stride: int,\n",
    "        expand_ratio: int,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        hidden_dim = int(round(inp * expand_ratio))\n",
    "        self.use_res_connect = self.stride == 1 and inp == oup\n",
    "\n",
    "        layers: List[nn.Module] = []\n",
    "        if expand_ratio != 1:\n",
    "            # pw\n",
    "            layers.append(ConvBNReLU(inp, hidden_dim, kernel_size=1, norm_layer=norm_layer))\n",
    "        layers.extend([\n",
    "            # dw\n",
    "            ConvBNReLU(hidden_dim, hidden_dim, stride=stride, groups=hidden_dim, norm_layer=norm_layer),\n",
    "            # pw-linear\n",
    "            nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "            norm_layer(oup),\n",
    "        ])\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "        self.out_channels = oup\n",
    "        self._is_cn = stride > 1\n",
    "        self.ff = torch.nn.quantized.FloatFunctional()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        if self.use_res_connect:\n",
    "            #return x + self.conv(x)\n",
    "            return self.ff.add(x, self.conv(x))\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int = 10,\n",
    "        width_mult: float = 1.0,\n",
    "        inverted_residual_setting: Optional[List[List[int]]] = None,\n",
    "        round_nearest: int = 8,\n",
    "        block: Optional[Callable[..., nn.Module]] = None,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_classes (int): Number of classes\n",
    "            width_mult (float): Width multiplier - adjusts number of channels in each layer by this amount\n",
    "            inverted_residual_setting: Network structure\n",
    "            round_nearest (int): Round the number of channels in each layer to be a multiple of this number\n",
    "            Set to 1 to turn off rounding\n",
    "            block: Module specifying inverted residual building block for mobilenet\n",
    "            norm_layer: Module specifying the normalization layer to use\n",
    "\n",
    "        \"\"\"\n",
    "        super(MobileNetV2, self).__init__()\n",
    "\n",
    "        if block is None:\n",
    "            block = InvertedResidual\n",
    "\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        input_channel = 32\n",
    "        last_channel = 1280\n",
    "\n",
    "        if inverted_residual_setting is None:\n",
    "            inverted_residual_setting = [\n",
    "                # t, c, n, s\n",
    "                [1, 16, 1, 1],\n",
    "                [6, 24, 2, 1],  # NOTE: change stride 2 -> 1 for CIFAR10/100\n",
    "                [6, 32, 3, 2],\n",
    "                [6, 64, 4, 2],\n",
    "                [6, 96, 3, 1],\n",
    "                [6, 160, 3, 2],\n",
    "                [6, 320, 1, 1],\n",
    "            ]\n",
    "\n",
    "        # only check the first element, assuming user knows t,c,n,s are required\n",
    "        if len(inverted_residual_setting) == 0 or len(inverted_residual_setting[0]) != 4:\n",
    "            raise ValueError(\"inverted_residual_setting should be non-empty \"\n",
    "                             \"or a 4-element list, got {}\".format(inverted_residual_setting))\n",
    "\n",
    "        # building first layer\n",
    "        input_channel = _make_divisible(input_channel * width_mult, round_nearest)\n",
    "        self.last_channel = _make_divisible(last_channel * max(1.0, width_mult), round_nearest)\n",
    "        features: List[nn.Module] = [ConvBNReLU(3, input_channel, stride=1, norm_layer=norm_layer)]  # NOTE: change stride 2 -> 1 for CIFAR10/100\n",
    "        # building inverted residual blocks\n",
    "        for t, c, n, s in inverted_residual_setting:\n",
    "            output_channel = _make_divisible(c * width_mult, round_nearest)\n",
    "            for i in range(n):\n",
    "                stride = s if i == 0 else 1\n",
    "                features.append(block(input_channel, output_channel, stride, expand_ratio=t, norm_layer=norm_layer))\n",
    "                input_channel = output_channel\n",
    "        # building last several layers\n",
    "        features.append(ConvBNReLU(input_channel, self.last_channel, kernel_size=1, norm_layer=norm_layer))\n",
    "        # make it nn.Sequential\n",
    "        self.features = nn.Sequential(*features)\n",
    "\n",
    "        # building classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(self.last_channel, num_classes),\n",
    "        )\n",
    "\n",
    "        # weight initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        # This exists since TorchScript doesn't support inheritance, so the superclass method\n",
    "        # (this one) needs to have a name other than `forward` that can be accessed in a subclass\n",
    "        x = self.features(x)\n",
    "        # Cannot use \"squeeze\" as batch-size can be 1\n",
    "        x = nn.functional.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floating Point and Quantized State Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_state1 = urllib.request.urlopen(\"https://drive.usercontent.google.com/download?id=1umVJExm8VeVSqIpEWlCVhMbJrNZeU-aw&export=download&confirm=t&uuid=0\")\n",
    "\n",
    "adversarial_state2 = urllib.request.urlopen(\"https://drive.usercontent.google.com/download?id=12Ux4pWLxK4gTr54eMN-Mds4adPMvjfNX&export=download&confirm=t&uuid=0\")\n",
    "\n",
    "adversarial_state3 = urllib.request.urlopen(\"https://drive.usercontent.google.com/download?id=19Nxyh3nIwR0KdXv_ZBk8Ur-DtQzuuct3&export=download&confirm=t&uuid=0\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "adversarial_quant_state = urllib.request.urlopen(\"https://drive.usercontent.google.com/download?id=1Z7raf4Eqpokh-SuzSdEIQRCXZSZOzhll&export=download&confirm=t&uuid=0\")\n",
    "\n",
    "adversarial_quant_state1 = urllib.request.urlopen(\"https://drive.usercontent.google.com/download?id=11kPJR9R95dfPx5RxrW_1B8TMKALTsgTO&export=download&confirm=t&uuid=0\")\n",
    "\n",
    "adversarial_quant_state2 = urllib.request.urlopen(\"https://drive.usercontent.google.com/download?id=18rWucu5ggvrwJ5IAsZl1WLSXsPET4WNN&export=download&confirm=t&uuid=0\")\n",
    "\n",
    "adversarial_quant_state3 = urllib.request.urlopen(\"https://drive.usercontent.google.com/download?id=1Xc_-v33EZP0XLnUE4MIGCs-OeuCUcmik&export=download&confirm=t&uuid=0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you want your own files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If you want to manually load the files or load your own versions, use the code below updating your path accordingly\n",
    "\n",
    "# Adversarial Model 1 https://drive.google.com/file/d/1umVJExm8VeVSqIpEWlCVhMbJrNZeU-aw/view?usp=sharing\n",
    "# Adversarial Model 2 https://drive.google.com/file/d/12Ux4pWLxK4gTr54eMN-Mds4adPMvjfNX/view?usp=sharing\n",
    "# Adversarial Model 3 https://drive.google.com/file/d/19Nxyh3nIwR0KdXv_ZBk8Ur-DtQzuuct3/view?usp=sharing\n",
    "\n",
    "\n",
    "# Quantized Model https://drive.google.com/file/d/1Z7raf4Eqpokh-SuzSdEIQRCXZSZOzhll/view?usp=sharing\n",
    "# Quantized Adversarial Model 1 https://drive.google.com/file/d/11kPJR9R95dfPx5RxrW_1B8TMKALTsgTO/view?usp=sharing\n",
    "# Quantized Adversarial Model 2 https://drive.google.com/file/d/18rWucu5ggvrwJ5IAsZl1WLSXsPET4WNN/view?usp=sharing\n",
    "# Quantized Adversarial Model 3 https://drive.google.com/file/d/1Xc_-v33EZP0XLnUE4MIGCs-OeuCUcmik/view?usp=sharing\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#path = \"~/Downloads/\"\n",
    "\n",
    "\n",
    "#adversarial_state1 = os.path.join(path, \"MobileNet_1it_CIFAR10_94.17acc.pkl\")\n",
    "#adversarial_state2 = os.path.join(path, \"MobileNet_2it_CIFAR10_93.58acc.pkl\")\n",
    "#adversarial_state3 = os.path.join(path, \"MobileNet_3it_CIFAR10_92.79acc.pkl\")\n",
    "\n",
    "#adversarial_quant_state1 = os.path.join(path, \"MobileNet_Quantized_NoRT_94.03.pt\")\n",
    "#adversarial_quant_state1 = os.path.join(path, \"MobileNet_Quantized_1RT_93.61.pt\")\n",
    "#adversarial_quant_state2 = os.path.join(path, \"MobileNet_Quantized_2RT_93.28.pt\")\n",
    "#adversarial_quant_state3 = os.path.join(path, \"MobileNet_Quantized_3RT_92.37.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading models to generate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_mobilenetv2_x1_4\", pretrained=True)\n",
    "\n",
    "\n",
    "mobilenet_1 = mobilenet\n",
    "mobilenet_1 = mobilenet_1.load_state_dict(torch.load(adversarial_state1))\n",
    "\n",
    "\n",
    "mobilenet_2 = mobilenet\n",
    "mobilenet_2 = mobilenet_2.load_state_dict(torch.load(adversarial_state2))\n",
    "\n",
    "mobilenet_3 = mobilenet\n",
    "mobilenet_3 = mobilenet_3.load_state_dict(torch.load(adversarial_state3))\n",
    "\n",
    "\n",
    "\n",
    "mobilenet_quant = MobileNetV2(width_mult = 1.4)\n",
    "mobilenet_quant = mobilenet_quant.load_state_dict(torch.load(adversarial_quant_state,map_location=torch.device('cpu')))\n",
    "\n",
    "mobilenet_quant_1 = MobileNetV2(width_mult = 1.4)\n",
    "mobilenet_quant_1 = mobilenet_quant_1.load_state_dict(torch.load(adversarial_quant_state1,map_location=torch.device('cpu')))\n",
    "\n",
    "mobilenet_quant_2 = MobileNetV2(width_mult = 1.4)\n",
    "mobilenet_quant_2 = mobilenet_quant_2.load_state_dict(torch.load(adversarial_quant_state2,map_location=torch.device('cpu')))\n",
    "\n",
    "mobilenet_quant_3 = MobileNetV2(width_mult = 1.4)\n",
    "mobilenet_quant_3 = mobilenet_quant_3.load_state_dict(torch.load(adversarial_quant_state3,map_location=torch.device('cpu')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1 , top5 = evaluator_testset(mobilenet, testloader)\n",
    "print('Normal Model: Initial accuracy on test images: Top-1: {}%  Top-5: {}% - FP32'.format(top1, top5))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "top1, top5 = evaluator_testset(mobilenet_quant, testloader)\n",
    "print('Quantized: Accuracy on test images: Top-1: {}%  Top-5: {}% - INT8'.format(top1, top5))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "top1 , top5 = evaluator_testset(mobilenet_1, testloader)\n",
    "print('Adversarial Training 1 Model: Initial accuracy on test images: Top-1: {}%  Top-5: {}% - FP32'.format(top1, top5))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "top1, top5 = evaluator_testset(mobilenet_quant_1, testloader)\n",
    "print('Quantized Adversarial Training 1: Accuracy on test images: Top-1: {}%  Top-5: {}% - INT8'.format(top1, top5))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "top1 , top5 = evaluator_testset(mobilenet_2, testloader)\n",
    "print('Adversarial Training 2 Model: Initial accuracy on test images: Top-1: {}%  Top-5: {}% - FP32'.format(top1, top5))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "top1, top5 = evaluator_testset(mobilenet_quant_2, testloader)\n",
    "print('Quantized Adversarial Training 2: Accuracy on test images: Top-1: {}%  Top-5: {}% - INT8'.format(top1, top5))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "top1 , top5 = evaluator_testset(mobilenet_3, testloader)\n",
    "print('Adversarial Training 3 Model: Initial accuracy on test images: Top-1: {}%  Top-5: {}% - FP32'.format(top1, top5))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "top1, top5 = evaluator_testset(mobilenet_quant_3, testloader)\n",
    "print('Quantized Adversarial Training 3: Accuracy on test images: Top-1: {}%  Top-5: {}% - INT8'.format(top1, top5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adversarial Example Generation Function\n",
    "\n",
    "There is no reason to run this. Adversarial examples on the test set are available on Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(optimizer, model, ver):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # Create the ART - PyTorch classifier\n",
    "    classifier = PyTorchClassifier(\n",
    "        model=model,\n",
    "        clip_values=(0.0, 1.0),\n",
    "        loss=criterion,\n",
    "        optimizer=optimizer,\n",
    "        preprocessing=((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)), #Normalization step shouldn't happen at the data. It's inserted here.\n",
    "        input_shape=(3, 32, 32),\n",
    "        nb_classes=10,\n",
    "        device_type = \"cpu\"\n",
    "    )\n",
    "    print(\"HopSkipJump Attack Initialization\")\n",
    "\n",
    "    attack = HopSkipJump(classifier,64,targeted = False,verbose = True)\n",
    "\n",
    "    x_test_eval_mobil = attack.generate(normalize_np(x_test[0:400]),y_test[0:400])\n",
    "\n",
    "    with open(\"mobilenet_evaluation_{}.pkl\".format(ver), 'wb') as f:\n",
    "        pickle.dump(x_test_eval_mobil, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(mobilenet.parameters(), lr=0.1, momentum=0.9, dampening=0,weight_decay=0.0005, nesterov=True)\n",
    "generator(optimizer, mobilenet, \"fp_0\")\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(mobilenet_1.parameters(), lr=0.0001, momentum=0.9, dampening=0,weight_decay=0.0005, nesterov=True)\n",
    "generator(optimizer, mobilenet_1, \"fp_1\")\n",
    "\n",
    "optimizer = optim.Adam(mobilenet_2.parameters(), lr=0.0001)\n",
    "generator(optimizer, mobilenet_2, \"fp_2\")\n",
    "\n",
    "optimizer = optim.Adam(mobilenet_3.parameters(), lr=5e-7)\n",
    "generator(optimizer, mobilenet_3, \"fp_3\")\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(mobilenet_quant.parameters(), lr=0.1, momentum=0.9, dampening=0,weight_decay=0.0005, nesterov=True)\n",
    "generator(optimizer, mobilenet_quant, \"int_0\")\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(mobilenet_quant_1.parameters(), lr=0.0001, momentum=0.9, dampening=0,weight_decay=0.0005, nesterov=True)\n",
    "generator(optimizer, mobilenet_quant_1, \"int_1\")\n",
    "\n",
    "optimizer = optim.Adam(mobilenet_quant_2.parameters(), lr=0.0001)\n",
    "generator(optimizer, mobilenet_quant_2, \"int_2\")\n",
    "\n",
    "optimizer = optim.Adam(mobilenet_quant_3.parameters(), lr=5e-7)\n",
    "generator(optimizer, mobilenet_quant_3, \"int_3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading pre-generated examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_test_mob_0 = urllib.request.urlopen(\"https://drive.usercontent.google.com/download?id=1s7HCO5M5wJ144M9-90QHUW7yDLuYWKYS&export=download&confirm=t&uuid=0\")\n",
    "x_test_mob_1 = urllib.request.urlopen(\"https://drive.usercontent.google.com/download?id=1D2193zDfSOKg8biFTOoPnLQgSaigMh2e&export=download&confirm=t&uuid=0\")\n",
    "x_test_mob_2 = urllib.request.urlopen(\"https://drive.usercontent.google.com/download?id=1zUyk_GAn2-H7qoqnm-N-VGY2Wb9hTXkl&export=download&confirm=t&uuid=0\")\n",
    "x_test_mob_3 = urllib.request.urlopen(\"https://drive.usercontent.google.com/download?id=1y_4dgV6Sn5KnjqayI-VABvFPxT0bVOyS&export=download&confirm=t&uuid=0\")\n",
    "\n",
    "x_test_mob_q0 = urllib.request.urlopen(\"https://drive.usercontent.google.com/download?id=1ltIXexqG4u7VCIYqXG7iH6BOHz649TIt&export=download&confirm=t&uuid=0\")\n",
    "x_test_mob_q1 = urllib.request.urlopen(\"https://drive.usercontent.google.com/download?id=10NIyPfZGfFBjumgZOIqsSE2-hJxrJ6ku&export=download&confirm=t&uuid=0\")\n",
    "x_test_mob_q2 = urllib.request.urlopen(\"https://drive.usercontent.google.com/download?id=1--IwSY5aoeeukky2y7UdvwLAoOqJcT-W&export=download&confirm=t&uuid=0\")\n",
    "x_test_mob_q3 = urllib.request.urlopen(\"https://drive.usercontent.google.com/download?id=1bkIpoQ7mmLWb-A7Z78b0HVDwxwhXunC4&export=download&confirm=t&uuid=0\")\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "If you want to manually load the files or load your own versions, use the code below updating your path accordingly\n",
    "\n",
    "# Initial   https://drive.google.com/file/d/1s7HCO5M5wJ144M9-90QHUW7yDLuYWKYS/view?usp=sharing\n",
    "# Adversarial 1 https://drive.google.com/file/d/1D2193zDfSOKg8biFTOoPnLQgSaigMh2e/view?usp=sharing\n",
    "# Adversarial 2 https://drive.google.com/file/d/1zUyk_GAn2-H7qoqnm-N-VGY2Wb9hTXkl/view?usp=sharing\n",
    "# Adversarial 3 https://drive.google.com/file/d/1y_4dgV6Sn5KnjqayI-VABvFPxT0bVOyS/view?usp=sharing\n",
    "\n",
    "\n",
    "# Quantized Initial https://drive.google.com/file/d/1ltIXexqG4u7VCIYqXG7iH6BOHz649TIt/view?usp=sharing\n",
    "# Quantized Adversarial 1 https://drive.google.com/file/d/10NIyPfZGfFBjumgZOIqsSE2-hJxrJ6ku/view?usp=sharing\n",
    "# Quantized Adversarial 2 https://drive.google.com/file/d/1--IwSY5aoeeukky2y7UdvwLAoOqJcT-W/view?usp=sharing\n",
    "# Quantized Adversarial 3 https://drive.google.com/file/d/1bkIpoQ7mmLWb-A7Z78b0HVDwxwhXunC4/view?usp=sharing\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#path = \"~/Downloads/\"\n",
    "\n",
    "\n",
    "#x_test_mob_0 = os.path.join(path, \"x_test_hop_mob_fp_400.pkl\")\n",
    "#x_test_mob_1 = os.path.join(path, \"MobileNetV2_fp_CIFAR10_1_ex.pkl\")\n",
    "#x_test_mob_2 = os.path.join(path, \"MobileNetV2_fp_CIFAR10_2_ex.pkl\")\n",
    "#x_test_mob_3 = os.path.join(path, \"MobileNetV2_fp_CIFAR10_3_ex.pkl\")\n",
    "\n",
    "#x_test_mob_q0 = os.path.join(path, \"x_test_hop_mobile_quant_400_psnr_check_No_retrain.pkl\")\n",
    "#x_test_mob_q1 = os.path.join(path, \"x_test_hop_mobile_quant_400_psnr_check_1_retrain.pkl\")\n",
    "#x_test_mob_q2 = os.path.join(path, \"x_test_hop_mobile_quant_400_psnr_check_2_retrain.pkl\")\n",
    "#x_test_mob_q3 = os.path.join(path, \"x_test_hop_mobile_quant_400_psnr_check_3_retrain.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PSNR Data Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mob_c_ts_0 = []\n",
    "mob_c_ts_1 = []\n",
    "mob_c_ts_2 = []\n",
    "mob_c_ts_3 = []\n",
    "\n",
    "mob_c_ts_q0 = []\n",
    "mob_c_ts_q1 = []\n",
    "mob_c_ts_q2 = []\n",
    "mob_c_ts_q3 = []\n",
    "\n",
    "\n",
    "for l in range(0,400):\n",
    "    mob_c_ts_0.append(PSNR(x_test[l],x_test_mob_0[l]))\n",
    "    mob_c_ts_1.append(PSNR(x_test[l],x_test_mob_1[l]))\n",
    "    mob_c_ts_2.append(PSNR(x_test[l],x_test_mob_2[l]))\n",
    "    mob_c_ts_3.append(PSNR(x_test[l],x_test_mob_3[l]))\n",
    "\n",
    "    mob_c_ts_q0.append(PSNR(x_test[l],x_test_mob_q0[l]))\n",
    "    mob_c_ts_q1.append(PSNR(x_test[l],x_test_mob_q1[l]))\n",
    "    mob_c_ts_q2.append(PSNR(x_test[l],x_test_mob_q2[l]))\n",
    "    mob_c_ts_q3.append(PSNR(x_test[l],x_test_mob_q3[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psnr = gmean(list(filter(lambda x: x != 0, mob_c_ts_0)))\n",
    "print(\"MobileNet FloatPoint CIFAR-10 Test 0 PSNR: {}dB\".format(psnr))\n",
    "print(\"\\n\")\n",
    "psnr = gmean(list(filter(lambda x: x != 0, mob_c_ts_1)))\n",
    "print(\"MobileNet FloatPoint CIFAR-10 Test 1 PSNR: {}dB\".format(psnr))\n",
    "print(\"\\n\")\n",
    "psnr = gmean(list(filter(lambda x: x != 0, mob_c_ts_2)))\n",
    "print(\"MobileNet FloatPoint CIFAR-10 Test 2 PSNR: {}dB\".format(psnr))\n",
    "print(\"\\n\")\n",
    "psnr = gmean(list(filter(lambda x: x != 0, mob_c_ts_3)))\n",
    "print(\"MobileNet FloatPoint CIFAR-10 Test 3 PSNR: {}dB\".format(psnr))\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "psnr = gmean(list(filter(lambda x: x != 0, mob_c_ts_q0)))\n",
    "print(\"MobileNet Int8 CIFAR-10 Test 0 PSNR: {}dB\".format(psnr))\n",
    "print(\"\\n\")\n",
    "psnr = gmean(list(filter(lambda x: x != 0, mob_c_ts_q1)))\n",
    "print(\"MobileNet Int8 CIFAR-10 Test 1 PSNR: {}dB\".format(psnr))\n",
    "print(\"\\n\")\n",
    "psnr = gmean(list(filter(lambda x: x != 0, mob_c_ts_q2)))\n",
    "print(\"MobileNet Int8 CIFAR-10 Test 2 PSNR: {}dB\".format(psnr))\n",
    "print(\"\\n\")\n",
    "psnr = gmean(list(filter(lambda x: x != 0, mob_c_ts_q3)))\n",
    "print(\"MobileNet Int8 CIFAR-10 Test 3 PSNR: {}dB\".format(psnr))\n",
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
